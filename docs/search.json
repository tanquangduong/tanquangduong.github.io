[
  {
    "objectID": "posts/unsloth-qwen-sft-lora.html#what-is",
    "href": "posts/unsloth-qwen-sft-lora.html#what-is",
    "title": "Finetuning Qwen2.5-3B with Unscloth",
    "section": "ğŸ¤ What is",
    "text": "ğŸ¤ What is\nExample of configuration:",
    "crumbs": [
      "ğŸš€ AI Station",
      "âš¡ **Supervised Fine Tuning (SFT)**",
      "1. Supervised Finetuning Qwen2.5-3B using LORA with Unscloth"
    ]
  },
  {
    "objectID": "posts/preference-dataset-dpo.html#what-is",
    "href": "posts/preference-dataset-dpo.html#what-is",
    "title": "Preference Dataset Creation for DPO Fine-Tuning",
    "section": "ğŸ¤ What is",
    "text": "ğŸ¤ What is\nExample of configuration:",
    "crumbs": [
      "ğŸš€ AI Station",
      "ğŸ§ª **Dataset for LLM**",
      "2. Preference Dataset Creation for DPO Fine-Tuning"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "âœ¨ AI/ML, MLOps, LLMOps",
    "section": "",
    "text": "Instruction Dataset Creation for Supervised Fine-Tuning\n\n\nLeveraging LLMs for creating instruction dataset for Supervised Fine-Tuning\n\n\n\ninstruction-dataset\n\n\n\n\n\n\nAug 27, 2024\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreference Dataset Creation for DPO Fine-Tuning\n\n\nLeveraging LLMs for creating preference dataset for DPO Fine-Tuning\n\n\n\npreference-dataset\n\n\n\n\n\n\nAug 27, 2024\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinetuning Qwen2.5-3B using DPO with Unsloth\n\n\nFinetuning Qwen2.5-3B with DPO using Unsloth on TinyStories prefrence dataset\n\n\n\nFinetuning\n\n\nDPO\n\n\nUnsloth\n\n\nQwen\n\n\n\n\n\n\nAug 24, 2024\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nFinetuning Qwen2.5-3B with Unscloth\n\n\nFinetuning Qwen2.5-3B with SFT-Lora using Unsloth on TinyStories instruction dataset\n\n\n\nFinetuning\n\n\nLORA\n\n\nUnsloth\n\n\n\n\n\n\nAug 24, 2024\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, Iâ€™m Quang. I am an AI/ML engineer. I live and work in Paris, France."
  },
  {
    "objectID": "posts/instruction-dataset-sft.html#what-is",
    "href": "posts/instruction-dataset-sft.html#what-is",
    "title": "Instruction Dataset Creation for Supervised Fine-Tuning",
    "section": "ğŸ¤ What is",
    "text": "ğŸ¤ What is\nExample of configuration:",
    "crumbs": [
      "ğŸš€ AI Station",
      "ğŸ§ª **Dataset for LLM**",
      "1. Instruction Dataset for Supervised Fine Tuning"
    ]
  },
  {
    "objectID": "posts/unsloth-qwen-dpo.html#what-is",
    "href": "posts/unsloth-qwen-dpo.html#what-is",
    "title": "Finetuning Qwen2.5-3B using DPO with Unsloth",
    "section": "ğŸ¤ What is",
    "text": "ğŸ¤ What is\nExample of configuration:",
    "crumbs": [
      "ğŸš€ AI Station",
      "âš¡ **Supervised Fine Tuning (SFT)**",
      "2. DPO Finetuning Qwen2.5-3B with Unsloth"
    ]
  }
]